# OpenTelemetry Collector Client Configuration
# Collects host metrics and sends to LGTM stack
#
# Replace <LGTM_HOST> with your Pi's IP address or hostname

receivers:
  # Host metrics (CPU, memory, disk, network, etc.)
  hostmetrics:
    collection_interval: 30s
    scrapers:
      cpu:
        metrics:
          system.cpu.utilization:
            enabled: true
      load:
      memory:
        metrics:
          system.memory.utilization:
            enabled: true
      disk:
      filesystem:
        metrics:
          system.filesystem.utilization:
            enabled: true
      network:
      paging:
      processes:
      process:
        include:
          match_type: regexp
          names: [".*"]
        mute_process_exe_error: true
        mute_process_io_error: true
        mute_process_user_error: true

  # Collect OTEL Collector's own metrics
  prometheus:
    config:
      scrape_configs:
        - job_name: 'otel-collector-client'
          scrape_interval: 30s
          static_configs:
            - targets: ['localhost:8888']

  # OTLP receiver for application telemetry
  otlp:
    protocols:
      grpc:
        endpoint: 0.0.0.0:4317
      http:
        endpoint: 0.0.0.0:4318

processors:
  # Batch for better performance
  batch:
    send_batch_size: 1000
    timeout: 10s

  # Memory limiter to prevent OOM
  memory_limiter:
    check_interval: 5s
    limit_mib: 256
    spike_limit_mib: 64

  # Add resource attributes to identify this host
  resourcedetection:
    detectors: [env, system]
    system:
      hostname_sources: ["os"]
      resource_attributes:
        host.id:
          enabled: true
        host.name:
          enabled: true
        host.arch:
          enabled: true
        os.description:
          enabled: true
        os.type:
          enabled: true

  # Add custom attributes
  resource:
    attributes:
      - key: deployment.environment
        value: homelab
        action: insert

exporters:
  # Send to LGTM stack via OTLP gRPC
  otlp:
    endpoint: <LGTM_HOST>:4316
    tls:
      insecure: true

  # Debug output (comment out in production)
  debug:
    verbosity: basic
    sampling_initial: 5
    sampling_thereafter: 200

extensions:
  health_check:
    endpoint: 0.0.0.0:13133

service:
  extensions: [health_check]

  pipelines:
    # Host metrics pipeline
    metrics:
      receivers: [hostmetrics, prometheus, otlp]
      processors: [memory_limiter, resourcedetection, resource, batch]
      exporters: [otlp, debug]

    # Traces pipeline (for application traces)
    traces:
      receivers: [otlp]
      processors: [memory_limiter, resourcedetection, resource, batch]
      exporters: [otlp, debug]

    # Logs pipeline (for application logs)
    logs:
      receivers: [otlp]
      processors: [memory_limiter, resourcedetection, resource, batch]
      exporters: [otlp, debug]

  telemetry:
    logs:
      level: warn
    metrics:
      level: basic
      readers:
        - pull:
            exporter:
              prometheus:
                host: "0.0.0.0"
                port: 8888
